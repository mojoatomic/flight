#!/usr/bin/env bash
# api.validate.sh - REST/HTTP API design patterns
# Generated by flight-domain-compile from api.flight
set -euo pipefail

# Script location for sourcing helpers
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Default: common file patterns
DEFAULT_PATTERNS="**/routes*.{js,ts} **/controller*.{js,ts} **/api/**/*.{js,ts} **/*Router*.java **/*Controller*.java **/views.py **/urls.py"
PASS=0
FAIL=0
WARN=0

red() { printf '\033[31m%s\033[0m\n' "$1"; }
green() { printf '\033[32m%s\033[0m\n' "$1"; }
yellow() { printf '\033[33m%s\033[0m\n' "$1"; }

check() {
    local name="$1"
    shift
    local result
    # Run check and filter out flight:ok suppression comments
    result=$("$@" 2>/dev/null | grep -v "flight:ok") || true
    if [[ -z "$result" ]]; then
        green "✅ $name"
        ((PASS++)) || true
    else
        red "❌ $name"
        printf '%s\n' "$result" | head -10 | sed 's/^/   /'
        ((FAIL++)) || true
    fi
}

warn() {
    local name="$1"
    shift
    local result
    # Run check and filter out flight:ok suppression comments
    result=$("$@" 2>/dev/null | grep -v "flight:ok") || true
    if [[ -z "$result" ]]; then
        green "✅ $name"
        ((PASS++)) || true
    else
        yellow "⚠️  $name"
        printf '%s\n' "$result" | head -5 | sed 's/^/   /'
        ((WARN++)) || true
    fi
}

printf '%s\n' "═══════════════════════════════════════════"
printf '%s\n' "  API Domain Validation"
printf '%s\n' "═══════════════════════════════════════════"
printf '\n'

# Source exclusions helper if available
if [[ -f "$SCRIPT_DIR/../exclusions.sh" ]]; then
    source "$SCRIPT_DIR/../exclusions.sh"
    FLIGHT_HAS_EXCLUSIONS=true
else
    FLIGHT_HAS_EXCLUSIONS=false
fi

# Handle arguments or use defaults
if [[ $# -gt 0 ]]; then
    FILES=("$@")
elif [[ "$FLIGHT_HAS_EXCLUSIONS" == true ]]; then
    # Use exclusions-aware file discovery
    mapfile -t FILES < <(flight_get_files "routes*.{js,ts}" "controller*.{js,ts}" "*.{js,ts}" "*Router*.java" "*Controller*.java" "views.py" "urls.py")
else
    # Fallback: use find (works on bash 3.2+, no globstar needed)
    mapfile -t FILES < <(find . -type f \( -name "routes*.{js,ts}" -o -name "controller*.{js,ts}" -o -name "*.{js,ts}" -o -name "*Router*.java" -o -name "*Controller*.java" -o -name "views.py" -o -name "urls.py" \) -not -path "*/node_modules/*" -not -path "*/.git/*" -not -path "*/dist/*" -not -path "*/build/*" 2>/dev/null | sort)
fi

if [[ ${#FILES[@]} -eq 0 ]]; then
    yellow "No files found matching default patterns"
    printf '%s\n' "  Patterns: **/routes*.{js,ts} **/controller*.{js,ts} **/api/**/*.{js,ts..."
    printf '\n'
    green "  RESULT: SKIP (no files)"
    exit 0
fi

printf 'Files: %d\n\n' "${#FILES[@]}"

# Filter to actual API endpoint files for API-specific checks
is_api_file() {
    local f="$1"
    # Path-based detection
    if [[ "$f" =~ (api/|routes/|endpoints/|handlers/|controllers/) ]]; then
        return 0
    fi
    # Content-based detection
    if grep -qE "(app|router|server|fastify|hono)\.(get|post|put|patch|delete|on)\(|NextResponse|\bResponse\.json|export\s+(async\s+)?function\s+(GET|POST|PUT|PATCH|DELETE)|@(Get|Post|Put|Delete|Patch|RequestMapping|GetMapping|PostMapping|api_view|action)\(|@(app|blueprint)\.route\(|http\.HandleFunc|func\s+\w*Handler" "$f" 2>/dev/null; then
        return 0
    fi
    return 1
}

API_ENDPOINT_FILES=()
for f in "${FILES[@]}"; do
    if is_api_file "$f"; then
        API_ENDPOINT_FILES+=("$f")
    fi
done

if [[ ${#API_ENDPOINT_FILES[@]} -gt 0 ]]; then
    printf 'API endpoint files: %d\n\n' "${#API_ENDPOINT_FILES[@]}"
else
    printf 'API endpoint files: 0 (some checks will be skipped)\n\n'
fi

printf '\n%s\n' "## NEVER Rules"

# N1: Verbs in URIs
check "N1: Verbs in URIs" \
    bash -c 'grep -En "['"'"'\"]/?)(create|delete|remove|update|get|fetch|add|edit|modify)([A-Z]|[_-][a-z])" "$@" | grep -v "flight:ok"' _ "${FILES[@]}"

# N2: 200 OK with Error Body
check "N2: 200 OK with Error Body" \
    grep -Ein "status\\(200\\).*['\"]?error['\"]?\\s*:|\\.ok\\(.*['\"]?error['\"]?\\s*:|status.*200.*success.*false" "${FILES[@]}"

# N3: Exposing Internal IDs in Pagination
check "N3: Exposing Internal IDs in Pagination" \
    grep -Ein "after_id|before_id|since_id|last_id|start_id" "${FILES[@]}"

# N5: Sensitive Data in Query Strings
check "N5: Sensitive Data in Query Strings" \
    grep -Ein "req\\.(query|params)(\\.(password|secret|api_key|token|auth)|\\[['\"]?(password|secret|api_key|token|auth))|(\\{[^}]*(password|secret|api_key|token|auth)[^}]*\\})\\s*=\\s*req\\.(query|params)" "${FILES[@]}"

# N6: Offset Pagination for Large Datasets
check "N6: Offset Pagination for Large Datasets" \
    grep -Ein "offset.*limit|page.*per_page|skip.*take" "${FILES[@]}"

# N7: 500 for Client Errors
check "N7: 500 for Client Errors" \
    grep -Ein "catch.*\\{[^}]*(status\\(500\\)|res\\.status\\s*=\\s*500)|(ValidationError|validate|invalid).*500|500.*(validation|invalid)" "${FILES[@]}"

# N8: CORS Wildcard with Credentials
check "N8: CORS Wildcard with Credentials" \
    bash -c '
        for f in "$@"; do
            if grep -qEi "origin.*\\*|Allow-Origin.*\\*" "$f" && grep -qEi "credentials.*true|withCredentials" "$f" 2>/dev/null; then
                echo "$f: condition matched"
            fi
        done
    ' _ "${FILES[@]}"

printf '\n%s\n' "## MUST Rules"

# M3: Consistent Error Response Format (RFC 7807)
if [[ ${#API_ENDPOINT_FILES[@]} -gt 0 ]]; then
    check "M3: Consistent Error Response Format (RFC 7807)" \
        bash -c 'grep -ql "application/problem\\+json|type.*title.*status|ProblemDetails" "$@" || echo "No RFC 7807 Problem Details pattern found"' _ "${API_ENDPOINT_FILES[@]}"
else
    green "✅ M3: Consistent Error Response Format (RFC 7807) (skipped - no API endpoint files)"
    ((PASS++)) || true
fi

# M4: Plural Nouns for Collection URIs
check "M4: Plural Nouns for Collection URIs" \
    grep -Ein "['\"]/(user|product|order|item|account|customer|payment)(/|['\"\"])" "${FILES[@]}"

# M5: Include Pagination Metadata in Response
check "M5: Include Pagination Metadata in Response" \
    bash -c 'for f in "$@"; do
  if grep -qEi "cursor|offset.*limit|page.*per_page|after_id|before_id" "$f" 2>/dev/null; then
    if ! grep -qEi "has_more|next_cursor|prev_cursor|total_pages|total_count|page_info" "$f" 2>/dev/null; then
      echo "$f: pagination patterns found but no response metadata"
    fi
  fi
done' _ "${FILES[@]}"

# M6: Version Your API from Day One
check "M6: Version Your API from Day One" \
    bash -c 'grep -qEi "/v[0-9]+([/'"'"'\"?]|\$)|version.*header|api-version" "$@" || echo "No API versioning detected"' _ "${FILES[@]}"

# M7: Rate Limit Headers
check "M7: Rate Limit Headers" \
    bash -c 'grep -qEi "x-ratelimit|rate.?limit|retry-after" "$@" || echo "No rate limiting headers detected"' _ "${FILES[@]}"

# M8: Location Header on 201 Created
check "M8: Location Header on 201 Created" \
    bash -c 'for f in "$@"; do
  if grep -qEi "status\(201\)|\.created\(" "$f" 2>/dev/null; then
    if ! grep -qEi "location.*header|header.*location|\.header\(.location" "$f" 2>/dev/null; then
      echo "$f: 201 responses found but no Location header"
    fi
  fi
done' _ "${FILES[@]}"

# M9: Content-Type Header on All Responses
check "M9: Content-Type Header on All Responses" \
    bash -c 'grep -qEi "content-type|\\.type\\(|\\.json\\(" "$@" || echo "No explicit Content-Type handling detected"' _ "${FILES[@]}"

printf '\n%s\n' "## SHOULD Rules"

# S1: Use HTTPS Always
warn "S1: Use HTTPS Always" \
    bash -c 'grep -Ein "http://[a-zA-Z]" "$@" | grep -v "localhost|127\\.0\\.0\\.1"' _ "${FILES[@]}"

# S3: Use ISO 8601 for Dates
if [[ ${#API_ENDPOINT_FILES[@]} -gt 0 ]]; then
    warn "S3: Use ISO 8601 for Dates" \
        bash -c 'grep -ql "toISOString|ISO.*8601|datetime|DateTimeFormatter" "$@" || echo "No ISO 8601 date handling detected"' _ "${API_ENDPOINT_FILES[@]}"
else
    green "✅ S3: Use ISO 8601 for Dates (skipped - no API endpoint files)"
    ((PASS++)) || true
fi

# S4: Consistent Field Naming Convention
warn "S4: Consistent Field Naming Convention" \
    bash -c 'for f in "$@"; do
  if grep -qE '"'"'"[a-z]+_[a-z]+"'"'"' "$f" 2>/dev/null && grep -qE '"'"'"[a-z]+[A-Z][a-z]+"'"'"' "$f" 2>/dev/null; then
    echo "$f: mixed snake_case and camelCase"
  fi
done' _ "${FILES[@]}"

# S8: Idempotency Keys for Non-Idempotent Operations
if [[ ${#API_ENDPOINT_FILES[@]} -gt 0 ]]; then
    warn "S8: Idempotency Keys for Non-Idempotent Operations" \
        bash -c 'grep -qEi "idempotency|idempotent" "$@" || echo "No idempotency handling detected"' _ "${API_ENDPOINT_FILES[@]}"
else
    green "✅ S8: Idempotency Keys for Non-Idempotent Operations (skipped - no API endpoint files)"
    ((PASS++)) || true
fi

# S9: CORS Headers for Browser Clients
if [[ ${#API_ENDPOINT_FILES[@]} -gt 0 ]]; then
    warn "S9: CORS Headers for Browser Clients" \
        bash -c 'grep -qEi "access-control-allow|cors\\(|cors\\.enable" "$@" || echo "No CORS handling detected"' _ "${API_ENDPOINT_FILES[@]}"
else
    green "✅ S9: CORS Headers for Browser Clients (skipped - no API endpoint files)"
    ((PASS++)) || true
fi

# S10: 202 Accepted for Long-Running Operations
warn "S10: 202 Accepted for Long-Running Operations" \
    bash -c 'has_async=false
has_202=false
for f in "$@"; do
  if grep -qEi "job|queue|worker|async.*process|background" "$f" 2>/dev/null; then
    has_async=true
  fi
  if grep -qEi "status\(202\)|\.accepted\(" "$f" 2>/dev/null; then
    has_202=true
  fi
done
if $has_async && ! $has_202; then
  echo "Async/background patterns found but no 202 Accepted responses"
fi' _ "${FILES[@]}"

# S11: OpenAPI/Swagger Specification
if [[ ${#API_ENDPOINT_FILES[@]} -gt 0 ]]; then
    warn "S11: OpenAPI/Swagger Specification" \
        bash -c '
            if ! ls openapi.yaml openapi.json swagger.yaml swagger.json api-spec.yaml api-spec.json docs/openapi.* docs/swagger.* 2>/dev/null | head -1 | grep -q .; then
                echo "No OpenAPI/Swagger spec found"
            fi
        ' 
else
    green "✅ S11: OpenAPI/Swagger Specification (skipped - no API endpoint files)"
    ((PASS++)) || true
fi

# S12: No Hardcoded URLs
warn "S12: No Hardcoded URLs" \
    bash -c 'grep -EHn "https?://[a-zA-Z0-9][a-zA-Z0-9.-]+\\.(com|io|net|org|dev|app)" "$@" | grep -v "localhost|127\\.0\\.0\\.1|example\\.com|^\\s*(//|#|/\\*|\\*)"' _ "${FILES[@]}"

# S13: Include Request IDs
warn "S13: Include Request IDs" \
    bash -c 'for f in "$@"; do
  if grep -qEi "res\.(status\(4|status\(5|json\(.*error" "$f" 2>/dev/null; then
    if ! grep -qEi "request_id|trace_id|requestId|traceId|x-request-id" "$f" 2>/dev/null; then
      echo "$f: error responses found but no request/trace ID handling"
    fi
  fi
done' _ "${FILES[@]}"

printf '\n%s\n' "## Info"

ENDPOINT_COUNT=$( (grep -cEi "(get|post|put|patch|delete)\s*\(" "${FILES[@]}" 2>/dev/null || true) | awk -F: '{s+=$NF}END{print s+0}')
printf 'ℹ️  Endpoint definitions: %s\n' "$ENDPOINT_COUNT"

STATUS_CODES=$( (grep -ohE "status\([0-9]{3}\)|\.status\s*=\s*[0-9]{3}" "${FILES[@]}" 2>/dev/null || true) | sort -u | wc -l | tr -d ' ')
printf 'ℹ️  Distinct status codes used: %s\n' "$STATUS_CODES"

PAGINATION_FILES=$( (grep -l "pagination|cursor|next_page|page_token|has_more" "${FILES[@]}" 2>/dev/null || true) | wc -l | tr -d ' ')
printf 'ℹ️  Files with pagination: %s\n' "$PAGINATION_FILES"

AUTH_FILES=$( (grep -l "authorization|authenticate|bearer|jwt|api.?key" "${FILES[@]}" 2>/dev/null || true) | wc -l | tr -d ' ')
printf 'ℹ️  Files with auth handling: %s\n' "$AUTH_FILES"

VALIDATION_FILES=$( (grep -l "validate|schema|joi|yup|zod|class-validator" "${FILES[@]}" 2>/dev/null || true) | wc -l | tr -d ' ')
printf 'ℹ️  Files with validation: %s\n' "$VALIDATION_FILES"

REQUEST_ID_FILES=$( (grep -li "request.?id|trace.?id|correlation.?id|x-request-id" "${FILES[@]}" 2>/dev/null || true) | wc -l | tr -d ' ')
printf 'ℹ️  Files with request ID handling: %s\n' "$REQUEST_ID_FILES"

printf '\n%s\n' "═══════════════════════════════════════════"
printf '  PASS: %d  FAIL: %d  WARN: %d\n' "$PASS" "$FAIL" "$WARN"
if [[ $FAIL -eq 0 ]]; then
    green "  RESULT: PASS"
else
    red "  RESULT: FAIL"
fi
printf '%s\n' "═══════════════════════════════════════════"

exit "$FAIL"
