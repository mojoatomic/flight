#!/usr/bin/env bash
# sql.validate.sh - Production SQL patterns for PostgreSQL/Supabase
# Generated by flight-domain-compile from sql.flight
set -euo pipefail

# Script location for sourcing helpers
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Default: common file patterns
DEFAULT_PATTERNS="**/*.sql **/*.js **/*.ts **/*.tsx **/*.py"
PASS=0
FAIL=0
WARN=0

red() { printf '\033[31m%s\033[0m\n' "$1"; }
green() { printf '\033[32m%s\033[0m\n' "$1"; }
yellow() { printf '\033[33m%s\033[0m\n' "$1"; }

check() {
    local name="$1"
    shift
    local result
    result=$("$@" 2>/dev/null) || true
    if [[ -z "$result" ]]; then
        green "✅ $name"
        ((PASS++)) || true
    else
        red "❌ $name"
        # Use subshell to prevent SIGPIPE from killing script with pipefail
        (printf '%s\n' "$result" | head -10 | sed 's/^/   /') || true
        ((FAIL++)) || true
    fi
}

warn() {
    local name="$1"
    shift
    local result
    result=$("$@" 2>/dev/null) || true
    if [[ -z "$result" ]]; then
        green "✅ $name"
        ((PASS++)) || true
    else
        yellow "⚠️  $name"
        # Use subshell to prevent SIGPIPE from killing script with pipefail
        (printf '%s\n' "$result" | head -5 | sed 's/^/   /') || true
        ((WARN++)) || true
    fi
}

printf '%s\n' "═══════════════════════════════════════════"
printf '%s\n' "  SQL Domain Validation"
printf '%s\n' "═══════════════════════════════════════════"
printf '\n'

# Source exclusions helper if available
if [[ -f "$SCRIPT_DIR/../exclusions.sh" ]]; then
    source "$SCRIPT_DIR/../exclusions.sh"
    FLIGHT_HAS_EXCLUSIONS=true
else
    FLIGHT_HAS_EXCLUSIONS=false
fi

# Handle arguments or use defaults
if [[ $# -gt 0 ]]; then
    FILES=("$@")
elif [[ "$FLIGHT_HAS_EXCLUSIONS" == true ]]; then
    # Use exclusions-aware file discovery
    mapfile -t FILES < <(flight_get_files "*.sql" "*.js" "*.ts" "*.tsx" "*.py")
else
    # Fallback: use find (works on bash 3.2+, no globstar needed)
    # Redirect stdin from /dev/null to prevent hanging in piped contexts (curl | bash)
    mapfile -t FILES < <(find . -type f \( -name "*.sql" -o -name "*.js" -o -name "*.ts" -o -name "*.tsx" -o -name "*.py" \) -not -path "*/node_modules/*" -not -path "*/.git/*" -not -path "*/dist/*" -not -path "*/build/*" < /dev/null 2>/dev/null | sort)
fi

if [[ ${#FILES[@]} -eq 0 ]]; then
    yellow "No files found matching default patterns"
    printf '%s\n' "  Patterns: **/*.sql **/*.js **/*.ts **/*.tsx **/*.py..."
    printf '\n'
    green "  RESULT: SKIP (no files)"
    exit 0
fi

printf 'Files: %d\n\n' "${#FILES[@]}"

printf '\n%s\n' "## NEVER Rules"

# N1: SELECT *
check "N1: SELECT *" \
    grep -Ein "SELECT\\s+\\*\\s+FROM" "${FILES[@]}"

# N2: String Interpolation in SQL
check "N2: String Interpolation in SQL" \
    grep -Ein "\\\`[^\\\`]*(SELECT|INSERT|UPDATE|DELETE).*\\\$\\{|(SELECT|INSERT|UPDATE|DELETE).*\"\\s*\\+|f\"[^\"]*(SELECT|INSERT|UPDATE).*\\{" "${FILES[@]}"

# N3: UPDATE/DELETE Without WHERE
check "N3: UPDATE/DELETE Without WHERE" \
    grep -Ein "DELETE\\s+FROM\\s+\\w+\\s*;" "${FILES[@]}"

# N4: LIKE with Leading Wildcard
check "N4: LIKE with Leading Wildcard" \
    grep -Ein "LIKE\\s+['\"]%[^'\"]+['\"]" "${FILES[@]}"

# N5: Functions on Columns in WHERE
check "N5: Functions on Columns in WHERE" \
    grep -Ein "WHERE.*(YEAR|MONTH|DAY|LOWER|UPPER|TRIM)\\s*\\(" "${FILES[@]}"

# N6: Large OFFSET Values
check "N6: Large OFFSET Values" \
    grep -Ein "OFFSET\\s+[0-9]{4,}|OFFSET\\s+\\\$" "${FILES[@]}"

# N7: Plain Text Password Column
# Path filtering for this rule
FILTERED_FILES=()
for __f in "${FILES[@]}"; do
    if ! ( [[ "$__f" == *.sql ]] ); then continue; fi
    FILTERED_FILES+=("$__f")
done
if [[ ${#FILTERED_FILES[@]} -gt 0 ]]; then
    check "N7: Plain Text Password Column" \
        bash -c '(grep -Ein "password\\s+(varchar|text|char)" "$@" | grep -v "password_hash" | grep -v "password_digest" | grep -v "hashed_password") || true' _ "${FILTERED_FILES[@]}"
else
    green "✅ N7: Plain Text Password Column (skipped - no matching files after path filter)"
    ((PASS++)) || true
fi

# N8: timestamp Without Timezone
# Path filtering for this rule
FILTERED_FILES=()
for __f in "${FILES[@]}"; do
    if ! ( [[ "$__f" == *.sql ]] ); then continue; fi
    FILTERED_FILES+=("$__f")
done
if [[ ${#FILTERED_FILES[@]} -gt 0 ]]; then
    check "N8: timestamp Without Timezone" \
        bash -c '(grep -Ein "\\stimestamp\\s" "$@" | grep -v "timestamptz" | grep -v "timestamp with time zone") || true' _ "${FILTERED_FILES[@]}"
else
    green "✅ N8: timestamp Without Timezone (skipped - no matching files after path filter)"
    ((PASS++)) || true
fi

# N9: float/real for Money
# Path filtering for this rule
FILTERED_FILES=()
for __f in "${FILES[@]}"; do
    if ! ( [[ "$__f" == *.sql ]] ); then continue; fi
    FILTERED_FILES+=("$__f")
done
if [[ ${#FILTERED_FILES[@]} -gt 0 ]]; then
    check "N9: float/real for Money" \
        grep -Ein "(price|cost|total|amount|balance|fee|rate)\\s+(float|real|double)" "${FILTERED_FILES[@]}"
else
    green "✅ N9: float/real for Money (skipped - no matching files after path filter)"
    ((PASS++)) || true
fi

printf '\n%s\n' "## SHOULD Rules"

# S1: Boolean Without NOT NULL DEFAULT
# Path filtering for this rule
FILTERED_FILES=()
for __f in "${FILES[@]}"; do
    if ! ( [[ "$__f" == *.sql ]] ); then continue; fi
    FILTERED_FILES+=("$__f")
done
if [[ ${#FILTERED_FILES[@]} -gt 0 ]]; then
    warn "S1: Boolean Without NOT NULL DEFAULT" \
        bash -c '(grep -Ein "\\s+boolean\\s*[,)]" "$@" | grep -v "NOT NULL") || true' _ "${FILTERED_FILES[@]}"
else
    green "✅ S1: Boolean Without NOT NULL DEFAULT (skipped - no matching files after path filter)"
    ((PASS++)) || true
fi

# S2: Missing RLS on user_id Tables
# Path filtering for this rule
FILTERED_FILES=()
for __f in "${FILES[@]}"; do
    if ! ( [[ "$__f" == *.sql ]] ); then continue; fi
    FILTERED_FILES+=("$__f")
done
if [[ ${#FILTERED_FILES[@]} -gt 0 ]]; then
    warn "S2: Missing RLS on user_id Tables" \
        bash -c '
for f in "$@"; do
    trigger_lines=$(grep -nE "user_id.*(REFERENCES|uuid)" "$f" 2>/dev/null)
    if [[ -n "$trigger_lines" ]]; then
        if ! grep -qE "ENABLE ROW LEVEL SECURITY" "$f" 2>/dev/null; then
            echo "$trigger_lines" | while IFS= read -r line; do
                linenum="${line%%:*}"
                echo "$f:$linenum: has user_id but no RLS"
            done
        fi
    fi
done
' _ "${FILTERED_FILES[@]}"
else
    green "✅ S2: Missing RLS on user_id Tables (skipped - no matching files after path filter)"
    ((PASS++)) || true
fi

# S5: Multiple Writes Without Transaction
# Path filtering for this rule
FILTERED_FILES=()
for __f in "${FILES[@]}"; do
    if [[ "$__f" == *.sql ]]; then continue; fi
    FILTERED_FILES+=("$__f")
done
if [[ ${#FILTERED_FILES[@]} -gt 0 ]]; then
    warn "S5: Multiple Writes Without Transaction" \
        bash -c '
for f in "$@"; do
    trigger_lines=$(grep -nE "INSERT INTO|UPDATE.*SET" "$f" 2>/dev/null)
    if [[ -n "$trigger_lines" ]]; then
        if ! grep -qE "BEGIN|transaction|\\.transaction" "$f" 2>/dev/null; then
            echo "$trigger_lines" | while IFS= read -r line; do
                linenum="${line%%:*}"
                echo "$f:$linenum: multiple writes without transaction"
            done
        fi
    fi
done
' _ "${FILTERED_FILES[@]}"
else
    green "✅ S5: Multiple Writes Without Transaction (skipped - no matching files after path filter)"
    ((PASS++)) || true
fi

# S6: Supabase .select() Without Columns
warn "S6: Supabase .select() Without Columns" \
    grep -En "\\.select\\(\\s*\\)" "${FILES[@]}"

printf '\n%s\n' "═══════════════════════════════════════════"
printf '  PASS: %d  FAIL: %d  WARN: %d\n' "$PASS" "$FAIL" "$WARN"
if [[ $FAIL -eq 0 ]]; then
    green "  RESULT: PASS"
else
    red "  RESULT: FAIL"
fi
printf '%s\n' "═══════════════════════════════════════════"

exit "$FAIL"
